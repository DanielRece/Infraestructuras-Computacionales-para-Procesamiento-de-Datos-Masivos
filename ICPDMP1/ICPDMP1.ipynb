{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.1: Contador de clientes valorados por países"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se partirá de los ficheros \"clientes.csv\" y \"countries.csv\" ubicados en el directorio relativo \"./datos\". El objetivo de este ejercicio es la producción de un fichero \"recuento_buenos.csv\" con la estructura que contendrá: una columna con los los distintos países del fichero \"countries.csv\" y una segunda columna con un valor numérico que corresponderá con la cantidad de clientes \"buenos\" de ese país. \n",
    "\n",
    "Con el fin de conseguir el fichero mencionado, se modifica el código proporcionado en el notebook \"mrjob-join.ipynb\" visto en el curso de la manera oportuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"./datos\")\n",
    "os.environ[\"HADOOP_HOME\"] = '/usr/lib/hadoop-3.3.6'\n",
    "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + os.environ[\"HADOOP_HOME\"] +\"/bin\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = os.environ[\"HADOOP_HOME\"] + \"/etc/hadoop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mrjob-recuento.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJoinModified(MRJob):\n",
    "\n",
    "    # Realiza la ordenación secuandaria\n",
    "    SORT_VALUES = True\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\",\")\n",
    "\n",
    "        if len(splits) == 2:  # Datos de paises\n",
    "            symbol = 'A'  # Ordena los datos de paises antes que los datos de personas\n",
    "            country2digit = splits[1] # Valor con el que realiza el cruce\n",
    "            country_name = splits[0]\n",
    "            yield country2digit, [symbol, splits]\n",
    "        else:  # Datos de personas\n",
    "            symbol = 'B'\n",
    "            country2digit = splits[2] # Valor con el que realiza el cruce\n",
    "            yield country2digit, [symbol, splits]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        countries = [] # Añade países\n",
    "        good_ratings_count = 0 # Recuento de buenos clientes por país\n",
    "\n",
    "        for value in values:\n",
    "            if value[0] == 'A':\n",
    "                countries.append([value[1][0]]) # Corchetes extra para adecuarse a la estructura especificada en el enunciado\n",
    "            if value[0] == 'B' and value[1][1] == 'bueno':\n",
    "                good_ratings_count += 1\n",
    "\n",
    "        for country in countries:\n",
    "            if good_ratings_count > 0: # No se añaden países sin clientes \"buenos\"\n",
    "                yield country, good_ratings_count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRJoinModified.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez modificado el código, se porcede a ejecutar en el entorno hadoop. Para ello, en primer lugar se suben los archivos al cluster. Finalmente se lanza la job que permite obtener el fichero resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /datos\n",
    "! hdfs dfs -put ./countries.csv  /datos\n",
    "! hdfs dfs -put ./clients.csv  /datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 mrjob-recuento.py hdfs:///datos -r hadoop --output-dir hdfs:///recuento_buenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -tail /recuento_buenos/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.2: País con mejores clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda parte, se querrá obtener algún país cuyo recuento de clientes buenos sea máximo. Para lograr el objetivo, se puede modificar el código anteriormente desarrollado incluyendo otro reducer que reciba el output del primero para que, ya teniendo todos la misma clave, se pueda calcular el máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mrjob-recuento-mejor.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRJoinModified(MRJob):\n",
    "\n",
    "    # Realiza la ordenación secuandaria\n",
    "    SORT_VALUES = True\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\",\")\n",
    "\n",
    "        if len(splits) == 2:  # Datos de paises\n",
    "            symbol = 'A'  # Ordena los datos de paises antes que los datos de personas\n",
    "            country2digit = splits[1] # Valor con el que realiza el cruce\n",
    "            country_name = splits[0]\n",
    "            yield country2digit, [symbol, splits]\n",
    "        else:  # Datos de personas\n",
    "            symbol = 'B'\n",
    "            country2digit = splits[2] # Valor con el que realiza el cruce\n",
    "            yield country2digit, [symbol, splits]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        countries = [] # Añade países\n",
    "        good_ratings_count = 0 # Recuento de buenos clientes por país\n",
    "\n",
    "        for value in values:\n",
    "            if value[0] == 'A':\n",
    "                countries.append([value[1][0]]) # Corchetes extra para adecuarse a la estructura especificada en el enunciado\n",
    "            if value[0] == 'B' and value[1][1] == 'bueno':\n",
    "                good_ratings_count += 1\n",
    "\n",
    "        for country in countries:\n",
    "            if good_ratings_count > 0: # No se añaden países sin clientes \"buenos\"\n",
    "                yield None, [country, good_ratings_count]\n",
    "\n",
    "    def reducer_max(self, _, values): # Segundo reducer sin clave para calcular el máximo\n",
    "        max_value = max(values, key = lambda x: x[1])\n",
    "        yield max_value[1], max_value[0]\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper, reducer=self.reducer),\n",
    "            MRStep(reducer=self.reducer_max)\n",
    "        ]\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRJoinModified.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -rm -r /recuento_mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 mrjob-recuento-mejor.py hdfs:///datos -r hadoop --output-dir hdfs:///recuento_mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -tail /recuento_mejor/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejervivio 1.3: Mejorando el país con mejores clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último apartado del ejercicio, se mejora el código anterio para que, en caso de haber más de un país con el número máximo de buenos clientes, se muestren todos. Nuevamente, se modificará el código del apartado anterior para lograr el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mrjob-recuento-mejores.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRJoinModified(MRJob):\n",
    "\n",
    "    # Realiza la ordenación secuandaria\n",
    "    SORT_VALUES = True\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\",\")\n",
    "\n",
    "        if len(splits) == 2:  # Datos de paises\n",
    "            symbol = 'A'  # Ordena los datos de paises antes que los datos de personas\n",
    "            country2digit = splits[1] # Valor con el que realiza el cruce\n",
    "            country_name = splits[0]\n",
    "            yield country2digit, [symbol, splits]\n",
    "        else:  # Datos de personas\n",
    "            symbol = 'B'\n",
    "            country2digit = splits[2] # Valor con el que realiza el cruce\n",
    "            yield country2digit, [symbol, splits]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        countries = [] # Añade países\n",
    "        good_ratings_count = 0 # Recuento de buenos clientes por país\n",
    "\n",
    "        for value in values:\n",
    "            if value[0] == 'A':\n",
    "                countries.append([value[1][0]]) # Corchetes extra para adecuarse a la estructura especificada en el enunciado\n",
    "            if value[0] == 'B' and value[1][1] == 'bueno':\n",
    "                good_ratings_count += 1\n",
    "\n",
    "        for country in countries:\n",
    "            if good_ratings_count > 0: # No se añaden países sin clientes \"buenos\"\n",
    "                yield None, [country, good_ratings_count]\n",
    "\n",
    "    def reducer_max(self, _, values): # Segundo reducer sin clave para calcular el máximo\n",
    "        max_count = -1\n",
    "        max_countries = []\n",
    "\n",
    "        for country, count in values:\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                max_countries = [country]\n",
    "            elif count == max_count:\n",
    "                max_countries.append(country)\n",
    "\n",
    "        for country in max_countries:\n",
    "            yield max_count, country\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper, reducer=self.reducer),\n",
    "            MRStep(reducer=self.reducer_max)\n",
    "        ]\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRJoinModified.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -rm -r /recuento_mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 mrjob-recuento-mejores.py hdfs:///datos -r hadoop --output-dir hdfs:///recuento_mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -tail /recuento_mejores/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios 2.1 y 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se crearán las bases de datos exigidas por el ejercicio. En este caso se opta por una base de datos interna para el fichero \"API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv\" puesto que al tratarse de un fichero que contiene, en esencia, series temporales, su rápido acceso y tratamiento es una prioridad. Por otra parte, para el fichero \"Metadata_Country_API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv\" se optará por una tabla externa por no ser una tabla que varíe su estructura (contiene datos estáticos sobre países y como mucho cambiará algún valor), ergo se prioriza la fácil actualización de la misma. \n",
    "\n",
    "Posteriormente se cargarán los datos desde los ficheros proporcionados (a los que se les ha hecho una ligera modificación para que solo contengan los datos pertinentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p hive_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"hive_datos\")\n",
    "os.environ[\"HIVE_HOME\"] = '/usr/lib/apache-hive-3.1.3-bin/'\n",
    "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + os.environ[\"HIVE_HOME\"] +\"/bin\"\n",
    "os.environ[\"HIVE_CONF_DIR\"] = os.environ[\"HIVE_HOME\"] + \"/conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /datos_hive\n",
    "! hdfs dfs -put ./Metadata_Country_API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv /datos_hive\n",
    "! hdfs dfs -put ./API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv /datos_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /datos_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiveql_script = \"\"\"\n",
    "CREATE database IF NOT EXISTS tablas_practica\n",
    "COMMENT 'BD para la realización de TP1'\n",
    "LOCATION '/datos_hive'\n",
    "With dbproperties ('Creada por'='Daniel Rece','Creada el'='19-Nov-2023');\n",
    "\n",
    "USE tablas_practica\n",
    "CREATE TABLE IF NOT EXISTS tabla_interna (\n",
    "    Country_Name STRING,\n",
    "    Country_Code STRING,\n",
    "    Indicator_Name STRING,\n",
    "    Indicator_Code STRING,\"\"\"\n",
    "\n",
    "for year in range(1960, 2023, 1):\n",
    "    hiveql_script = hiveql_script + f\"\"\"\n",
    "    {year} DOUBLE,\"\"\"\n",
    "\n",
    "hiveql_script = hiveql_script[0:len(hiveql_script)-1] + f\"\"\") \n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';\"\"\"\n",
    "\n",
    "with open('crear_tabla_interna.hql', 'w') as file:\n",
    "    file.write(hiveql_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///\" -f crear_tabla_interna.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e \"load data inpath '/datos_hive/API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv' into table tabla_interna;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiveql_script = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS tabla_externa (\n",
    "    Country_Name STRING,\n",
    "    Country_Code STRING,\n",
    "    Region STRING,\n",
    "    Income_Group STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LOCATION '/datos_hive/Metadata_Country_API_SE.PRM.CMPT.FE.ZS_DS2_es_csv_v2_5641106.csv';\n",
    "\"\"\"\n",
    "with open('crear_tabla_externa.hql', 'w') as file:\n",
    "    file.write(hiveql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -f crear_tabla_externa.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la vista exigida en el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiveql_view = \"\"\"\n",
    "CREATE VIEW vista_pais_info AS\n",
    "SELECT\n",
    "    i.Country_Name,\n",
    "    i.Country_Code,\n",
    "    i.`2018` AS Rate_2018,\n",
    "    e.Income_Group\n",
    "FROM\n",
    "    tabla_interna i\n",
    "JOIN\n",
    "    tabla_externa e\n",
    "ON\n",
    "    i.Country_Code = e.Country_Code;\n",
    "\"\"\"\n",
    "\n",
    "with open('crear_vista_pais_info.hql', 'w') as file:\n",
    "    file.write(hiveql_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -f crear_vista_pais_info.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean y ejecutan consultas que respondan a las preguntas realizadas en el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa en el año 2018 en España\n",
    "tasa_2018_esp = \"\"\"\n",
    "SELECT Rate_2018\n",
    "FROM vista_pais_info\n",
    "WHERE Country_Name = 'Spain';\n",
    "\"\"\"\n",
    "\n",
    "# Media de las tasas del 2018 para países de ingreso bajo\n",
    "media_tasa_2018_ingreso_bajo = \"\"\"\n",
    "SELECT AVG(Rate_2018) AS Avg_Rate_2018_LowIncome\n",
    "FROM vista_pais_info\n",
    "WHERE Income_Group = '\"Países de ingreso bajo\"';\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Cinco países con mayor tasa en 2020\n",
    "top_paises_2020 = \"\"\"\n",
    "SELECT Country_Name, Rate_2020\n",
    "FROM (\n",
    "    SELECT Country_Name, Rate_2020,\n",
    "    ROW_NUMBER() OVER (ORDER BY Rate_2020 DESC) AS rank\n",
    "    FROM vista_pais_info\n",
    ") ranked\n",
    "WHERE rank <= 5;\n",
    "\"\"\"\n",
    "\n",
    "# Número de países de Oriente Medio y Norte de Ágfrica (excluido altos ingresos) en cada grupo de ingresos\n",
    "paises_por_grupo_ingresos = \"\"\"\n",
    "SELECT Income_Group, COUNT(*) AS Num_Countries\n",
    "FROM vista_pais_info\n",
    "WHERE Region = '\"Oriente Medio y Norte de África (excluido altos ingresos)\"'\n",
    "GROUP BY Income_Group;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('consulta1.hql', 'w') as file:\n",
    "    file.write(tasa_2018_esp)\n",
    "with open('consulta2.hql', 'w') as file:\n",
    "    file.write(media_tasa_2018_ingreso_bajo)\n",
    "with open('consulta3.hql', 'w') as file:\n",
    "    file.write(top_paises_2020)\n",
    "with open('consulta4.hql', 'w') as file:\n",
    "    file.write(paises_por_grupo_ingresos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e consulta1.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e consulta2.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e consulta3.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e consulta4.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar este ejercicio, se emplea el dataset: https://www.kaggle.com/datasets/dillonmyrick/high-school-student-performance-and-demographics/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -put ./student_math_clean.csv /datos_hive\n",
    "! hdfs dfs -put ./student_portuguese_clean.csv /datos_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_math = \"\"\"\n",
    "CREATE database IF NOT EXISTS students\n",
    "COMMENT 'BD para la realización de TP1, ejercicio 2.5'\n",
    "LOCATION '/datos_hive'\n",
    "With dbproperties ('Creada por'='Daniel Rece','Creada el'='20-Nov-2023');\n",
    "\n",
    "USE students\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS student_math (\n",
    "    school STRING,\n",
    "    sex STRING,\n",
    "    age INT,\n",
    "    address_type STRING,\n",
    "    family_size STRING,\n",
    "    parent_status STRING,\n",
    "    mother_education STRING,\n",
    "    father_education STRING,\n",
    "    mother_job STRING,\n",
    "    father_job STRING,\n",
    "    reason STRING,\n",
    "    guardian STRING,\n",
    "    travel_time STRING,\n",
    "    study_time STRING,\n",
    "    class_failures INT,\n",
    "    school_support STRING,\n",
    "    family_support STRING,\n",
    "    extra_paid_classes STRING,\n",
    "    activities STRING,\n",
    "    nursery STRING,\n",
    "    higher_ed STRING,\n",
    "    internet STRING,\n",
    "    romantic_relationship STRING,\n",
    "    family_relationship INT,\n",
    "    free_time INT,\n",
    "    social INT,\n",
    "    weekday_alcohol INT,\n",
    "    weekend_alcohol INT,\n",
    "    health INT,\n",
    "    absences INT,\n",
    "    grade_1 INT,\n",
    "    grade_2 INT,\n",
    "    final_grade INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LOCATION '/datos_hive/student_math_clean.csv';\n",
    "\"\"\"\n",
    "table_port = \"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS student_portuguese (\n",
    "    school STRING,\n",
    "    sex STRING,\n",
    "    age INT,\n",
    "    address_type STRING,\n",
    "    family_size STRING,\n",
    "    parent_status STRING,\n",
    "    mother_education STRING,\n",
    "    father_education STRING,\n",
    "    mother_job STRING,\n",
    "    father_job STRING,\n",
    "    reason STRING,\n",
    "    guardian STRING,\n",
    "    travel_time STRING,\n",
    "    study_time STRING,\n",
    "    class_failures INT,\n",
    "    school_support STRING,\n",
    "    family_support STRING,\n",
    "    extra_paid_classes STRING,\n",
    "    activities STRING,\n",
    "    nursery STRING,\n",
    "    higher_ed STRING,\n",
    "    internet STRING,\n",
    "    romantic_relationship STRING,\n",
    "    family_relationship INT,\n",
    "    free_time INT,\n",
    "    social INT,\n",
    "    weekday_alcohol INT,\n",
    "    weekend_alcohol INT,\n",
    "    health INT,\n",
    "    absences INT,\n",
    "    grade_1 INT,\n",
    "    grade_2 INT,\n",
    "    final_grade INT\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LOCATION '/datos_hive/student_portuguese_clean.csv';\n",
    "\"\"\"\n",
    "\n",
    "with open('tabla_estudiantes_matematicas.hql', 'w') as file:\n",
    "    file.write(table_math)\n",
    "with open('tabla_estudiantes_portugues.hql', 'w') as file:\n",
    "    file.write(table_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///\" -f tabla_estudiantes_matematicas.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! beeline -u \"jdbc:hive2:///students\" -f tabla_estudiantes_portugues.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///students\" -e \"load data inpath '/datos_hive/student_math_clean.csv' into table tabla_interna;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///tablas_practica\" -e \"load data inpath '/datos_hive/student_portuguese_clean.csv' into table student_portuguese;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos comandos, ya se habría creado y cargado el dataset. A continuación, se procederá a hacer las consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta consulta permite comprobar si las notas de matemáticas y portugués de los distintos alumnos están inversamente correlacionadas en casos no extremos.\n",
    "\n",
    "consulta1 = \"\"\"\n",
    "CREATE TEMPORARY TABLE if not exists i_values_temp AS\n",
    "SELECT i_value\n",
    "FROM (\n",
    "    SELECT 5 AS i_value UNION ALL\n",
    "    SELECT 6 UNION ALL\n",
    "    SELECT 7 UNION ALL\n",
    "    SELECT 8 UNION ALL\n",
    "    SELECT 9 UNION ALL\n",
    "    SELECT 10 UNION ALL\n",
    "    SELECT 11 UNION ALL\n",
    "    SELECT 12 UNION ALL\n",
    "    SELECT 13 UNION ALL\n",
    "    SELECT 14 UNION ALL\n",
    "    SELECT 15\n",
    ") i_values;\n",
    "\n",
    "CREATE TEMPORARY TABLE if not exists j_values_temp AS\n",
    "SELECT j_value\n",
    "FROM (\n",
    "    SELECT 5 AS j_value UNION ALL\n",
    "    SELECT 6 UNION ALL\n",
    "    SELECT 7 UNION ALL\n",
    "    SELECT 8 UNION ALL\n",
    "    SELECT 9 UNION ALL\n",
    "    SELECT 10 UNION ALL\n",
    "    SELECT 11 UNION ALL\n",
    "    SELECT 12 UNION ALL\n",
    "    SELECT 13 UNION ALL\n",
    "    SELECT 14 UNION ALL\n",
    "    SELECT 15\n",
    ") j_values;\n",
    "\n",
    "SELECT i_value, j_value, COUNT(*) AS student_count\n",
    "FROM i_values_temp i\n",
    "JOIN j_values_temp j ON ABS(i.i_value - j.j_value) <= 10\n",
    "JOIN student_math m \n",
    "JOIN student_portuguese p \n",
    "ON (m.final_grade > i.i_value) AND (p.final_grade < j.j_value)\n",
    "GROUP BY i.i_value, j.j_value\n",
    "ORDER BY student_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "with open('consulta_ej2_5_1.hql', 'w') as file:\n",
    "    file.write(consulta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///students\" -e consulta1_ej2_5_1.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calcula el promedio de notas finales por diferentes grupos de edad y el nivel de tiempo de estudio. El cruce se realiza por distintos campos al no disponer de un identificador unívoco.\n",
    "consulta2 = \"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN m.age BETWEEN 15 AND 17 THEN '15-17' \n",
    "        WHEN m.age BETWEEN 18 AND 20 THEN '18-20' \n",
    "        ELSE '21+'\n",
    "    END AS age_group,\n",
    "    CASE \n",
    "        WHEN m.study_time = '2 to 5 hours' THEN 'Moderate'\n",
    "        WHEN m.study_time = '5 to 10 hours' THEN 'Above Average'\n",
    "        WHEN m.study_time = '>10 hours' THEN 'High'\n",
    "        ELSE 'Low'\n",
    "    END AS study_time_level,\n",
    "    AVG(m.final_grade) AS avg_final_grade_math\n",
    "    AVG(p.final_grade) AS avg_final_grade_por\n",
    "FROM student_math m \n",
    "JOIN student_portuguese p \n",
    "ON m.school = p.school AND m.sex = p.sex AND m.age = p.age AND m.address_type = p.address_type AND m.family_size = p.family_size AND m.parent_status = p.parent_status \n",
    "GROUP BY \n",
    "    CASE \n",
    "        WHEN m.age BETWEEN 15 AND 17 THEN '15-17' \n",
    "        WHEN m.age BETWEEN 18 AND 20 THEN '18-20' \n",
    "        ELSE '21+'\n",
    "    END,\n",
    "    CASE \n",
    "        WHEN m.study_time = '2 to 5 hours' THEN 'Moderate'\n",
    "        WHEN m.study_time = '5 to 10 hours' THEN 'Above Average'\n",
    "        WHEN m.study_time = '>10 hours' THEN 'High'\n",
    "        ELSE 'Low'\n",
    "    END\n",
    "ORDER BY avg_final_grade DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "with open('consulta_ej2_5_2.hql', 'w') as file:\n",
    "    file.write(consulta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! beeline -u \"jdbc:hive2:///students\" -e consulta1_ej2_5_2.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
